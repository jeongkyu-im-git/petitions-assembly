{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 국민동의청원 분류하기\n",
    "\n",
    "본 프로젝트는 국민동의청원 사이트에서 참여 인원이 높은 청원 글들의 특징을 학습하여, 새로운 청원 글이 입력되었을 때 학습된 글들과 유사성을 계산하여 주목 받을 만한 글인지 아닌지를 판단하도록 합니다.\n",
    "\n",
    "국민동의청원 사이트 [링크](https://petitions.assembly.go.kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[원본 데이터 추출]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://petitions.assembly.go.kr/api/petits?pageIndex=1&recordCountPerPage=10000&sort=AGRE_CO-&searchCondition=sj&searchKeyword=&petitRealmCode=&sttusCode=PETIT_FORMATN,CMIT_FRWRD,PETIT_END&resultCode=BFE_OTHBC_WTHDRAW,PROGRS_WTHDRAW,PETIT_UNACPT,APPRVL_END_DSUSE,ETC_TRNSF&notInColumn=RESULT_CODE&beginDate=20200101&endDate=20240731&ageCd='\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "response_body = response.json()\n",
    "\n",
    "petitions = response_body\n",
    "df_orignal = pd.DataFrame(petitions)\n",
    "\n",
    "df_orignal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[학습 데이터 추출 및 저장]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 필요한 데이터 항목을 추출합니다.\n",
    "\n",
    "# 크롤링 원본 데이터에서 딥러닝 할 dataset 컬럼 패핑\n",
    "colums_to_extract = {\n",
    "    'rowNum': 'rowno',\n",
    "    'petitRealmNm': 'category',\n",
    "    'petitSj': 'title',\n",
    "    'petitCn': 'content',\n",
    "    'agreCo': 'count',\n",
    "    'agreBeginDe': 'start',\n",
    "    'agreEndDe': 'end'\n",
    "}\n",
    "\n",
    "# 원본 데이터에서 특정 열을 추출하고 열 이름 변경하여 새로운 df에 할당\n",
    "df_extracted = df_orignal[list(colums_to_extract.keys())].rename(columns=colums_to_extract)\n",
    "\n",
    "# 날짜 형식 변환(원본 yyyy-MM-dd 24HH:MI:SS, 변환 yyyy-MM-dd)\n",
    "df_extracted['start'] = pd.to_datetime(df_extracted['start']).dt.strftime('%Y-%m-%d')\n",
    "df_extracted['end'] = pd.to_datetime(df_extracted['end']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "df_extracted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file_path = 'data/petitions-assembly-dataset.csv'\n",
    "df_extracted.to_csv(dataset_file_path, index=False)\n",
    "\n",
    "print(f\"추출된 데이터가 {dataset_file_path}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 학습 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 로드\n",
    "df = pd.read_csv(dataset_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 전 출력\n",
    "df.loc[1]['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def remove_white_space(text):\n",
    "    return re.sub(r'[\\t\\r\\n\\f\\v]', ' ', str(text))\n",
    "\n",
    "def remove_special_char(text):\n",
    "    return re.sub('[^ ㄱ-ㅣ가-힣 0-9]+', ' ', str(text))\n",
    "\n",
    "# title 전처리\n",
    "df.title = df.title.apply(remove_white_space)\n",
    "df.title = df.title.apply(remove_special_char)\n",
    "\n",
    "# content 전처리\n",
    "df.content = df.content.apply(remove_white_space)\n",
    "df.content = df.content.apply(remove_special_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 후 출력\n",
    "df.loc[1]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 토크나이징 및 변수 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[토크나이징]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import platform\n",
    "\n",
    "try:\n",
    "    okt = Okt()\n",
    "except:\n",
    "    print('JAVA_HOME not found.')\n",
    "\n",
    "    # get platform\n",
    "    platform_name = platform.system()\n",
    "    print(f'Platform name : {platform_name}')\n",
    "\n",
    "    if platform_name=='Darwin':\n",
    "        JVM_PATH = '/Library/Java/JavaVirtualMachines/zulu-1.8.0.jdk/Contents/Home/jre/lib/jli/libjli.dylib'\n",
    "    else:\n",
    "        JVM_PATH = 'C:\\\\Library\\\\Java\\\\jdk-17.0.12\\\\bin\\\\server\\\\jvm.dll'\n",
    "    okt = Okt(JVM_PATH)\n",
    "\n",
    "df['title_token'] = df.title.apply(okt.morphs)\n",
    "print('title_token completed.')\n",
    "df['content_token'] = df.content.apply(okt.nouns)\n",
    "print('content_token completed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[파생변수 생성]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_final'] = df.title_token + df.content_token\n",
    "\n",
    "# 국민동의청원에서는 int형이므로 생략함.\n",
    "# df['count'] = df['count'].replace({',' : ''}, regex = True).apply(lambda x : int(x))\n",
    "\n",
    "print(df.dtypes)\n",
    "\n",
    "df['label'] = df['count'].apply(lambda x: 'Yes' if x>=1000 else 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df[['token_final', 'label']]\n",
    "\n",
    "df_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[데이터 엑셀로 저장]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_path = 'data/df_drop.csv'\n",
    "df_drop.to_csv(df_drop_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"토큰 데이터가 {df_drop_path}에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 단어 임베딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[단어 임베딩]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "embedding_model = Word2Vec(df_drop['token_final'],\n",
    "                           sg=1,\n",
    "                           vector_size=100,\n",
    "                           window=2,\n",
    "                           min_count=1,\n",
    "                           workers=4\n",
    "                           )\n",
    "\n",
    "print(embedding_model)\n",
    "\n",
    "model_result = embedding_model.wv.most_similar(\"탄핵\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[임베드 모델 저장 및 로드]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "tokens_w2v_path = 'data/petitions_tokens_w2v.pkl'\n",
    "\n",
    "# 모델 저장\n",
    "embedding_model.wv.save_word2vec_format(tokens_w2v_path) \n",
    "# 모델 로드\n",
    "loaded_model = KeyedVectors.load_word2vec_format(tokens_w2v_path)\n",
    "\n",
    "model_result = loaded_model.most_similar(\"탄핵\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 실험 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[데이터셋 분할 및 저장]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import RandomState\n",
    "\n",
    "rng = RandomState()\n",
    "\n",
    "tr = df_drop.sample(frac=0.8, random_state=rng)\n",
    "val = df_drop.loc[(~df_drop.index.isin(tr.index))]\n",
    "\n",
    "train_file_path = 'data/train.csv'\n",
    "validation_file_path = 'data/validation.csv'\n",
    "tr.to_csv(train_file_path, index=False, encoding='utf-8-sig')\n",
    "val.to_csv(validation_file_path, index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Field 클래스 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext \n",
    "from torchtext.data import Field\n",
    "\n",
    "def tokenizer(text):\n",
    "    return re.sub('[\\[\\]\\']', '', str(text)).split(', ')\n",
    "\n",
    "TEXT = Field(tokenize=tokenizer)\n",
    "LABEL = Field(sequential=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[데이터 불러오기]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset\n",
    "\n",
    "train, validation = TabularDataset.splits(\n",
    "    path='data/',\n",
    "    train='train.csv',\n",
    "    validation='validation.csv',\n",
    "    format='csv',\n",
    "    fields=[('text', TEXT), ('label', LABEL)],\n",
    "    skip_header=True\n",
    ")\n",
    "\n",
    "print(f'Train: {train[0].text}, {train[0].label}')\n",
    "print(f'Validation: {validation[0].text}, {validation[0].label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[단어장 및 DataLoader 정의]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "vectors = Vectors(name=tokens_w2v_path)\n",
    "\n",
    "TEXT.build_vocab(train, vectors=vectors, min_freq=1, max_size=None)\n",
    "LABEL.build_vocab(train)\n",
    "\n",
    "vocab = TEXT.vocab\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_iter, validation_iter = BucketIterator.splits(\n",
    "    datasets=(train, validation),\n",
    "    batch_sizes=8,\n",
    "    device=device,\n",
    "    sort=False\n",
    ")\n",
    "\n",
    "print(f'임베팅 벡터의 개수와 차원 {TEXT.vocab.vectors.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "petitions-cpu-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
